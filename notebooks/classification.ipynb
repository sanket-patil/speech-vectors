{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "import librosa\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import os\n",
    "import random\n",
    "from matplotlib.pyplot import specgram\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    np.nan_to_num(X)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "\n",
    "# def parse_audio_files(parent_dir, sub_dirs, file_ext='*.wav'):\n",
    "#     features, labels = np.empty((0, 193)), np.empty(0)\n",
    "#     for label, sub_dir in enumerate(sub_dirs):\n",
    "#         for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "#             mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "#             ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "#             features = np.vstack([features,ext_features])\n",
    "#             labels = np.append(labels, os.path.split(fn)[-1].split('-')[1])\n",
    "#     return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def parse_audio_files(parent_dir, sub_dirs, classes, file_ext='*.ogg'):\n",
    "    features, labels = np.empty((0, 193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, classes.get(sub_dir))\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sound Sample Classes\n",
      "--------------------\n",
      "rooster\n",
      "coughing\n",
      "insects\n",
      "laughing\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/esc-50'\n",
    "sample_dir = os.path.join(data_dir, 'sample')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "print 'Sound Sample Classes'\n",
    "print '--------------------'\n",
    "for d in os.listdir(sample_dir):\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dict = dict()\n",
    "for d in os.listdir(sample_dir):\n",
    "    sample_class_dir = os.path.join(sample_dir, d)\n",
    "    samples_dict[d] = [os.path.join(sample_class_dir, f) for f in os.listdir(sample_class_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfccs, chroma, mel, contrast,tonnetz = extract_feature(samples_dict.get('insects')[0])\n",
    "ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "mfccs, chroma, mel, contrast,tonnetz = extract_feature(samples_dict.get('insects')[0])\n",
    "ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "print len(ext_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 193)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,193))\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.71008667e+02   1.11177134e+02  -2.66969894e+01   1.64818867e+01\n",
      "   -4.28178103e-01  -1.32390633e+01   1.21125811e+00  -5.36048044e+00\n",
      "   -1.12257893e+01  -1.54257043e+01  -1.81542393e+01  -1.80371958e+01\n",
      "   -1.07932755e+01  -8.53481359e+00  -6.64451044e+00  -1.93843792e+00\n",
      "   -1.12454952e+01  -1.68509149e+01  -1.28325805e+01  -1.23412747e+01\n",
      "   -9.02519197e+00  -5.68524379e+00  -5.22570074e+00  -7.41173323e+00\n",
      "   -1.38022800e+01  -1.52868561e+01  -1.31671584e+01  -9.81586918e+00\n",
      "   -6.73705615e+00  -8.49936622e+00  -1.17248014e+01  -1.46298240e+01\n",
      "   -1.01961189e+01   3.74741798e+00   2.14096003e+01   3.56850792e+01\n",
      "    3.83353708e+01   2.89771481e+01   1.19066973e+01  -2.89713765e+00\n",
      "    1.59088475e-01   3.19025165e-01   3.33885749e-01   1.52062355e-01\n",
      "    1.77843989e-01   2.93502119e-01   8.13136173e-01   8.85314120e-01\n",
      "    3.31957176e-01   1.98507119e-01   3.94651468e-01   3.02763397e-01\n",
      "    8.68044150e-02   1.83963744e-02   1.35715236e-02   2.39104148e-02\n",
      "    1.39743146e-01   6.72779917e+00   4.90004694e+02   2.73282780e+02\n",
      "    8.93248234e-01   5.59734983e-02   1.70156021e-02   2.59211479e-02\n",
      "    9.61986968e-01   4.17390167e+01   8.62789041e+01   5.58839101e+00\n",
      "    4.88813554e-02   6.79680806e-03   4.78441937e-03   1.48819929e-01\n",
      "    3.20957326e+00   1.22941049e+01   4.12018888e+00   9.93672660e-02\n",
      "    4.37581389e-03   2.98869747e-03   1.00605985e-02   2.59755824e-01\n",
      "    7.90625275e-01   6.10696306e-01   7.46318680e-02   5.72895169e-03\n",
      "    3.96717497e-03   9.20663652e-02   1.41673099e+00   6.02122098e+00\n",
      "    6.44586128e+00   1.63331443e+00   1.09673649e-01   5.98863026e-03\n",
      "    1.22476459e-02   7.09265921e-02   2.40077103e-01   3.19510478e-01\n",
      "    8.61640183e-02   6.65731303e-03   1.16871322e-02   1.31723973e-01\n",
      "    2.78013311e-01   1.51962472e-01   4.00416660e-02   6.17122649e-03\n",
      "    7.81794417e-02   1.96918157e-01   1.51670048e-01   3.32580226e-02\n",
      "    7.61031437e-03   3.29178922e-02   6.04684941e-02   1.53753055e-02\n",
      "    7.11120307e-03   1.68225158e-02   2.11778417e-02   8.03014126e-03\n",
      "    1.11053473e-02   3.95009299e-02   3.38501458e-02   1.31685055e-02\n",
      "    2.22509392e-02   2.41385683e-02   1.13896898e-02   1.60631428e-02\n",
      "    1.59461956e-02   6.22479372e-03   8.93443731e-03   1.07098259e-02\n",
      "    6.18478379e-03   9.12808856e-03   7.54452137e-03   9.15637982e-03\n",
      "    7.81352579e-03   6.35637785e-03   8.36853838e-03   6.21336188e-03\n",
      "    6.53785908e-03   4.66720774e-03   4.59873942e-03   3.29128604e-03\n",
      "    2.36636812e-03   1.52167571e-03   1.33269869e-03   1.14961995e-03\n",
      "    1.01464148e-03   5.93145876e-04   4.99635008e-04   4.98640086e-04\n",
      "    5.03423621e-04   4.61343924e-04   4.50671235e-04   4.80561314e-04\n",
      "    3.64230392e-04   3.45524261e-04   3.06339818e-04   2.57827978e-04\n",
      "    1.84518869e-04   1.36144799e-04   9.49975459e-05   9.42402109e-05\n",
      "    9.45126118e-05   9.04012059e-05   7.84361819e-05   5.63061283e-05\n",
      "    3.90798580e-05   2.93396714e-05   2.11918386e-05   1.61612281e-05\n",
      "    1.21721234e-05   9.67922533e-06   6.89963830e-06   5.43285045e-06\n",
      "    3.83645753e-06   2.90355287e-06   2.12411428e-06   1.89239558e-06\n",
      "    1.59997136e-06   1.24610975e-06   5.06919169e-07   1.81620320e-07\n",
      "    3.73000535e+01   2.72948934e+01   2.49868627e+01   2.53811632e+01\n",
      "    1.81814493e+01   1.97994342e+01   3.85436245e+01   3.70963525e-02\n",
      "   -2.24606709e-02   1.88734775e-01  -2.03544718e-01   5.38986268e-02\n",
      "    1.56129083e-02]]\n"
     ]
    }
   ],
   "source": [
    "features = np.vstack([features,ext_features])\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = os.path.join(data_dir, 'sample')\n",
    "sub_dirs = ['laughing', 'coughing', 'insects', 'rooster']\n",
    "classes = {'laughing': 0, 'coughing': 1, 'insects': 2, 'rooster': 3}\n",
    "features, labels = parse_audio_files(sample_dir, sub_dirs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 193)\n"
     ]
    }
   ],
   "source": [
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = one_hot_encode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 193)\n",
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    one_hot, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_units_one = 50 \n",
    "n_hidden_units_two = 50\n",
    "\n",
    "n_classes = 4\n",
    "n_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units_one, input_dim=n_dim, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(n_hidden_units_two, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(n_classes, kernel_initializer='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 0s - loss: 1.3210 - acc: 0.3636     \n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 0s - loss: 1.1869 - acc: 0.5530     \n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 0s - loss: 1.0305 - acc: 0.6136     \n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 0s - loss: 0.8609 - acc: 0.6970     \n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 0s - loss: 0.7235 - acc: 0.7500     \n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 0s - loss: 0.6231 - acc: 0.7879     \n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 0s - loss: 0.5371 - acc: 0.8258     \n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 0s - loss: 0.4258 - acc: 0.8788     \n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 0s - loss: 0.3891 - acc: 0.8712     \n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 0s - loss: 0.3196 - acc: 0.9015     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03e13c67d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s\n",
      "acc: 83.33%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
